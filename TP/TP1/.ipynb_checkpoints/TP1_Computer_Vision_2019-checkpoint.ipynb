{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>TP1 Computer Vision 2019</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "### 1. Basics of image acquisition and representation\n",
    "1.1. Loading and displaying OpenCV images<br>\n",
    "1.2. BGR to RGB<br>\n",
    "1.3. Rectangular ROI (Region Of Interest)<br>\n",
    "1.4. Basic operations on images<br>\n",
    "\n",
    "### 2. Low-pass image filtering\n",
    "2.1 Average filtering<br>\n",
    "2.2. Uniform blurring<br>\n",
    "2.2. Gaussian blurring<br>\n",
    "\n",
    "### 3. High-pass image filtering\n",
    "3.1. Unsharp filtering<br>\n",
    "3.2. Image Gradient<br>\n",
    "\n",
    "### 4. Edge detection\n",
    "4.1. First order image derivatives<br>\n",
    "4.2. Second order image derivatives<br>\n",
    "4.3. Canny algorithm<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Basics of image acquisition and representation\n",
    "We first import the modules we will need in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0098428faf61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m                     \u001b[0;31m# Numerical algorithms on arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m                             \u001b[0;31m# OpenCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m   \u001b[0;31m# Plot library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcm\u001b[0m             \u001b[0;31m# Image color map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtools\u001b[0m                           \u001b[0;31m# A few helpers to plot multiple images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np                     # Numerical algorithms on arrays\n",
    "import cv2                             # OpenCV\n",
    "from matplotlib import pyplot as plt   # Plot library\n",
    "import matplotlib.cm as cm             # Image color map \n",
    "import tools                           # A few helpers to plot multiple images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   1.1. Loading and displaying OpenCV images\n",
    "\n",
    "You can use the imread function in order to read an image from a specific file path. Let's try to load some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a grayscale image\n",
    "boat = cv2.imread('Images/boat.png')\n",
    "\n",
    "# Load a color image\n",
    "plane_color = cv2.imread('Images/airplane.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Load a color image in grayscale format\n",
    "plane_gray = cv2.imread('Images/airplane.png', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format used by OpenCV is the folowing : \n",
    "\n",
    "<code>(height, width, channels (if several))</code>\n",
    "\n",
    "stored in a numpy ndarray with unsigned integers from 0 to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Object type in which the image is stored: \", type(plane_color))\n",
    "print(\"Shape of the array with a color image: \", plane_color.shape)\n",
    "print(\"Shape of the array with a gray image: \", plane_gray.shape)\n",
    "print(\"Data type is : \", plane_color.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the images are stored in numpy arrays, we can display them using a built-in function of OpenCV.\n",
    "\n",
    "To keep the image on screen, you need to use the keyboard binding function cv2.waitKey(int). Its argument is the time in milliseconds. The function waits for specified milliseconds for any keyboard event. If you press any key in that time, the program continues. If 0 is passed, it waits indefinitely for a key stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image\n",
    "cv2.imshow( 'Grayscale image', boat)\n",
    "cv2.imshow( 'Color image', plane_color)\n",
    "cv2.imshow( 'Color image displayed in grayscale', plane_gray)\n",
    "\n",
    "# Keyboard binding function. \n",
    "cv2.waitKey( 0)\n",
    "\n",
    "# Destroy all the previously opened windows\n",
    "cv2.destroyAllWindows( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. BGR to RGB\n",
    "\n",
    "Let us note that the channels are organised as follows with openCV :\n",
    "* 1 : Blue\n",
    "* 2 : Green\n",
    "* 3 : Red\n",
    "\n",
    "which can be incompatible with other computer vision frameworks that use the usual red, green, blue format. You can however re-arrange the channels as you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b,g,r = cv2.split( plane_color)\n",
    "plane_rgb = cv2.merge( [r,g,b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Rectangular ROI (Region Of Interest)\n",
    "\n",
    "You can select a sub-part of the images using the numpy slicing process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_roi = plane_color[ 128:293,26:508,:]\n",
    "cv2.imshow( 'Color image', plane_roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Basic operations on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load a grayscale image as grayscale and float between 0.0 and 1.0!\n",
    "\n",
    "cameraman_grey = cv2.imread( 'Images/cameraman.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "cameraman_grey = cameraman_grey.astype(\"float\")/255\n",
    "\n",
    "print(\"Data type is : \", cameraman_grey.dtype)\n",
    "print(\"Minimal value is :\",  np.min(cameraman_grey))\n",
    "print(\"Maximal value is :\",  np.max(cameraman_grey))\n",
    "\n",
    "# Darker image\n",
    "cameraman_darker = cameraman_grey/2\n",
    "\n",
    "# Brighter image for certain pixels\n",
    "cameraman_lighter = np.where( cameraman_grey > 0.5, 1.0, cameraman_grey * 2)\n",
    "\n",
    "\n",
    "#Concatenate and display the images\n",
    "frame = np.concatenate((np.concatenate((cameraman_grey, cameraman_darker),axis=1),cameraman_lighter),axis=1)\n",
    "\n",
    "cv2.imshow(\"Darker and Lighter\",frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows( )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Low-pass image filtering\n",
    "## 2.1. Average filtering\n",
    "The most basic linear filtering is certainly a moving average of the image. This may be achieved with the 'cv2.filter2D' function in OpenCV, which computes the 2D convolution product of an image with a kernel. The function parameters are :\n",
    "* one input image ('boat'),\n",
    "* the pixel type of the result image ('-1' tells that the pixel type of the result image should be the same than the pixel type of the input image; 'GRAYSCALE' in our case)\n",
    "* and one kernel (an uniform kernel; 'ka7').\n",
    "\n",
    "\n",
    "'tools.multiPlot' is a helper function to plot multiple images whose parameters are:\n",
    "* the number 'N' and 'M' of lines and columns of the array of image to plot (here N==1 and M==2),\n",
    "* a tuple or list of the 'NxM' images to plot,\n",
    "* a tuple or list of the image titles,\n",
    "* an optional tuple or list of the image color map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boat = cv2.imread( 'Images/boat.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "ka7 = np.ones( ( 7, 7), dtype=float) / 49\n",
    "\n",
    "boat_avg = cv2.filter2D( boat, -1, ka7)\n",
    "\n",
    "tools.multiPlot( 1, 2, ( boat, boat_avg), ( 'Original image', 'Average filtering (7x7 kernel)'), cmap_tuple=( cm.gray, cm.gray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'cv2.filter2D' has also an optional parameter 'borderType' to choose the kind of border conditions you would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boat = cv2.imread( 'Images/boat.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "ka7 = np.ones( ( 15, 15), dtype=float) / 225\n",
    "\n",
    "# Various border types, image boundaries are denoted with '|'\n",
    "#\n",
    "#   BORDER_CONSTANT:      iiiiii|abcdefgh|iiiiiii  with some specified 'i'\n",
    "#   BORDER_REPLICATE:     aaaaaa|abcdefgh|hhhhhhh\n",
    "#   BORDER_REFLECT:       fedcba|abcdefgh|hgfedcb\n",
    "#   BORDER_REFLECT_101:   gfedcb|abcdefgh|gfedcba\n",
    "#   BORDER_WRAP:          cdefgh|abcdefgh|abcdefg\n",
    "#\n",
    "#   BORDER_ISOLATED:      Consider a ROI as an isolated image\n",
    "#\n",
    "boat_avg_const = cv2.filter2D( boat, -1, ka7, borderType=cv2.BORDER_CONSTANT)\n",
    "boat_avg_isol = cv2.filter2D( boat, -1, ka7, borderType=cv2.BORDER_ISOLATED)\n",
    "boat_avg_replic = cv2.filter2D( boat, -1, ka7, borderType=cv2.BORDER_REPLICATE)\n",
    "boat_avg_reflec = cv2.filter2D( boat, -1, ka7, borderType=cv2.BORDER_REFLECT)\n",
    "boat_avg_wrap = cv2.filter2D( boat, -1, ka7, borderType=cv2.BORDER_WRAP)\n",
    "\n",
    "tools.multiPlot( 2, 3, ( boat, boat_avg_const, boat_avg_isol, boat_avg_replic, boat_avg_reflec, boat_avg_wrap),\n",
    "                       ( 'Original image', 'Constant Border Type', 'Isolated Border Type',\n",
    "                         'Replicate Border Type', 'Reflect Border Type', 'Wrap Border Type'),\n",
    "                       cmap_tuple=( cm.gray, cm.gray, cm.gray, cm.gray, cm.gray, cm.gray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Uniform blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boat = cv2.imread( 'Images/boat.png', cv2.IMREAD_GRAYSCALE)\n",
    "boat_blur = cv2.blur( boat, ( 7, 7))\n",
    "\n",
    "tools.multiPlot( 1, 2, ( boat, boat_blur), ( 'Original image', 'Blurred image (7x7 kernel)'),\n",
    "                       cmap_tuple=( cm.gray, cm.gray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Gaussian blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boat = cv2.imread( 'Images/boat.png', cv2.IMREAD_GRAYSCALE)\n",
    "boat_gauss_blur = cv2.GaussianBlur( boat, ( 7, 7), 0)\n",
    "\n",
    "tools.multiPlot( 1, 2, ( boat, boat_gauss_blur), ( 'Original image', 'Gaussian blurring (7x7 kernel)'),\n",
    "                      cmap_tuple=( cm.gray, cm.gray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. High-Pass filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Unsharp filtering\n",
    "The principle is to remove low frequencies from the image using:\n",
    "\n",
    "$g(x,y) = f(x,y)-f_{smooth}(x,y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, fixed\n",
    "\n",
    "boat = cv2.imread( 'Images/boat.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def update( kernel_size=9, strength=3.0):\n",
    "    boat_avg = cv2.GaussianBlur( boat, ( kernel_size, kernel_size), 0)\n",
    "\n",
    "    boat_sharp = tools.saturate_cast_uint8( strength * boat - ( strength - 1.0) * boat_avg)\n",
    "\n",
    "    tools.multiPlot( 1, 2, ( boat, boat_sharp), ( 'Original image', 'Sharpened image'),\n",
    "                           cmap_tuple=( cm.gray, cm.gray))\n",
    "    \n",
    "interact(update, kernel_size = [3, 5, 7, 9, 11, 13, 15, 17, 19] , strength = (1.5, 5.0, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Image gradient\n",
    "### 3.2.1. The Sobel filter\n",
    "We compute the first (discrete) derivative of the image in the X direction with the Sobel filter\n",
    "\n",
    "$$G_{X}^{(I)} (x,y) = K^{SobelX}(x,y) \\otimes I(x,y)$$\n",
    "\n",
    "where\n",
    "\n",
    "$$K^{SobelX}(x,y)=\n",
    "     \\begin{bmatrix}\n",
    "      +1 & 0 & -1 \\\\\n",
    "      +2 & 0 & -2 \\\\\n",
    "      +1 & 0 & -1\n",
    "     \\end{bmatrix} =\n",
    "     \\begin{bmatrix}\n",
    "      1 \\\\\n",
    "      2 \\\\\n",
    "      1 \n",
    "     \\end{bmatrix} \\otimes\n",
    "     \\begin{bmatrix}\n",
    "      +1 & 0 & -1\n",
    "     \\end{bmatrix}=\\left\\{\n",
    "      \\begin{bmatrix}\n",
    "      1 \\\\\n",
    "      1 \n",
    "     \\end{bmatrix} \\otimes \n",
    "      \\begin{bmatrix}\n",
    "      1 \\\\\n",
    "      1 \n",
    "     \\end{bmatrix}\\right\\} \\otimes \\left\\{\n",
    "     \\begin{bmatrix}\n",
    "      +1 &  -1\n",
    "     \\end{bmatrix} \\otimes \n",
    "     \\begin{bmatrix}\n",
    "      1 & 1\n",
    "     \\end{bmatrix} \\right\\}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread( 'Images/Pattern_inspection2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 2D filter\n",
    "K_SobelX = np.array( ( ( 1, 0, -1), (2, 0, -2), (1, 0, -1)), dtype=float)\n",
    "img_sobelX1 = tools.saturate_cast_uint8( 127.0 + cv2.filter2D( img, cv2.CV_64F, K_SobelX))\n",
    "\n",
    "# Two 1D filters\n",
    "K_SobelX_X = np.array( ( 1, 0, -1), dtype=float)\n",
    "K_SobelX_Y = np.array( ( 1, 2, 1), dtype=float)\n",
    "img_sobelX2 = tools.saturate_cast_uint8( 127.0 + cv2.sepFilter2D( img, cv2.CV_64F, K_SobelX_X, K_SobelX_Y))\n",
    "\n",
    "# Predefined Sobel filter\n",
    "img_sobelX3 = tools.saturate_cast_uint8( 127.0 + cv2.Sobel( img, cv2.CV_32F, 1, 0, ksize=3))\n",
    "\n",
    "tools.multiPlot( 2, 2, ( img, img_sobelX1, img_sobelX2, img_sobelX3),\n",
    "                ( 'Original image', 'Sobel X - 2D Filter', 'Sobel X - 2 Separated 1D Filters', 'Sobel X - OpenCV'),\n",
    "                cmap_tuple=( cm.gray, cm.gray, cm.gray, cm.gray))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. The Scharr's kernel\n",
    "We may also use the Scharr's kernel instead of the Sobel's kernel for gradient\n",
    "\n",
    "$$K^{ScharrX}(x,y)=\n",
    "     \\begin{bmatrix}\n",
    "      +3 & 0 & -3 \\\\\n",
    "      +10 & 0 & -10 \\\\\n",
    "      +3 & 0 & -3\n",
    "     \\end{bmatrix} =\n",
    "     \\begin{bmatrix}\n",
    "      3 \\\\\n",
    "      10 \\\\\n",
    "      3 \n",
    "     \\end{bmatrix} \\otimes\n",
    "     \\begin{bmatrix}\n",
    "      +1 & 0 & -1\n",
    "     \\end{bmatrix}=\\left\\{\n",
    "      \\begin{bmatrix}\n",
    "      3 \\\\\n",
    "      1 \n",
    "     \\end{bmatrix} \\otimes \n",
    "      \\begin{bmatrix}\n",
    "      1 \\\\\n",
    "      3 \n",
    "     \\end{bmatrix}\\right\\} \\otimes \\left\\{\n",
    "     \\begin{bmatrix}\n",
    "      +1 &  -1\n",
    "     \\end{bmatrix} \\otimes \n",
    "     \\begin{bmatrix}\n",
    "      1 & 1\n",
    "     \\end{bmatrix} \\right\\}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread( 'Images/Pattern_inspection2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "img_sobelX = tools.saturate_cast_uint8( 127.0 + cv2.Sobel( img, cv2.CV_32F, 1, 0, ksize=3))\n",
    "\n",
    "K_Scharr_X = np.array( ( ( -3, 0, 3), (-10, 0, 10), (-3, 0, 3)), dtype=float)\n",
    "img_scharrX = tools.saturate_cast_uint8( 127.0 + cv2.filter2D( img, cv2.CV_64F, K_Scharr_X))\n",
    "\n",
    "#img_scharrX = tools.saturate_cast_uint8( 127.0 + cv2.Scharr( img, cv2.CV_32F, 1, 0))\n",
    "\n",
    "tools.multiPlot( 1, 2, ( img_sobelX, img_scharrX),\n",
    "                ( 'Sobel X', 'Scharr X'),\n",
    "                cmap_tuple=( cm.gray, cm.gray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3. Image gradient in Y direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread( 'Images/Pattern_inspection2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "img_sobelY = tools.saturate_cast_uint8( 127.0 + cv2.Sobel( img, cv2.CV_32F, 0, 1, ksize=3))\n",
    "\n",
    "img_scharrY = tools.saturate_cast_uint8( 127.0 + cv2.Scharr( img, cv2.CV_32F, 0, 1) / 4.0)\n",
    "\n",
    "tools.multiPlot( 3, 1, ( img, img_sobelY, img_scharrY),\n",
    "                ( 'Original image', 'Sobel Y', 'Scharr Y'),\n",
    "                cmap_tuple=( cm.gray, cm.gray, cm.gray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Edge detection\n",
    "## 4.1. First order image derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread( 'Images/Pattern_inspection2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "ksize = 3\n",
    "img_sobelX = cv2.Sobel( img, cv2.CV_32F, 1, 0, ksize=ksize)\n",
    "img_sobelY = cv2.Sobel( img, cv2.CV_32F, 0, 1, ksize=ksize)\n",
    "img_sobel2 = tools.saturate_cast_uint8( np.sqrt( 0.5 * ( img_sobelX * img_sobelX + img_sobelY * img_sobelY)))\n",
    "\n",
    "img_scharrX = cv2.Scharr( img, cv2.CV_32F, 1, 0) / 4.0\n",
    "img_scharrY = cv2.Scharr( img, cv2.CV_32F, 0, 1) / 4.0\n",
    "img_scharr = tools.saturate_cast_uint8( np.sqrt( 0.5 * ( img_scharrX * img_scharrX + img_scharrY * img_scharrY)))\n",
    "\n",
    "tools.multiPlot( 1, 3, ( img, img_sobel2, img_scharr),\n",
    "                ( 'Original image', 'Sobel2', 'Scharr'),\n",
    "                cmap_tuple=( cm.gray, cm.gray, cm.gray))\n",
    "\n",
    "#img_sobel1 = tools.saturate_cast_uint8( 0.5 * ( np.abs( img_sobelX) + np.abs( img_sobelY)))\n",
    "#kfact = 1.0 / np.power( 2.0, 2 * ksize - 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Second order image derivatives\n",
    "### 4.2.1. Laplacian\n",
    "\n",
    "The Laplacian is the sum of the second (discrete) derivatives of the image\n",
    "\n",
    "$$\\Delta I(x,y) = \\frac{\\partial ^2 I(x,y)} {x^2} + \\frac{\\partial ^2 I(x,y)} {y^2}. $$\n",
    "\n",
    "It may be implemented by\n",
    "\n",
    "$$L^{(I)} (x,y) = K^{Laplacian}(x,y) \\otimes I(x,y)$$\n",
    "\n",
    "where\n",
    "\n",
    "$$K^{Laplacian}(x,y)=\n",
    "     \\begin{bmatrix}\n",
    "      0  & -1 &  0 \\\\\n",
    "      -1 & +4 & -1 \\\\\n",
    "      0  & -1 &  0\n",
    "     \\end{bmatrix} \\quad\\mathrm{or}\\quad\n",
    "  K^{Laplacian}(x,y)=\n",
    "     \\begin{bmatrix}\n",
    "      -1 & -1 & -1 \\\\\n",
    "      -1 & +8 & -1 \\\\\n",
    "      -1 & -1 & -1\n",
    "     \\end{bmatrix}     \n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread( 'Images/Pattern_inspection2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "img_sobelX = cv2.Sobel( img, cv2.CV_32F, 1, 0, ksize=3)\n",
    "img_sobelY = cv2.Sobel( img, cv2.CV_32F, 0, 1, ksize=3)\n",
    "img_sobel = tools.saturate_cast_uint8( np.sqrt( 0.5 * ( img_sobelX * img_sobelX + img_sobelY * img_sobelY)))\n",
    "\n",
    "# 2D filter\n",
    "K_Laplacian = np.array( ( ( -1, -1, -1), (-1, 8, -1), (-1, -1, -1)), dtype=float)\n",
    "img_laplacian = tools.saturate_cast_uint8( cv2.filter2D( img, cv2.CV_64F, K_Laplacian))\n",
    "\n",
    "## With Sobel's filter\n",
    "#img_sobelX2 = cv2.Sobel( img, cv2.CV_32F, 2, 0, ksize=3)\n",
    "#img_sobelY2 = cv2.Sobel( img, cv2.CV_32F, 0, 2, ksize=3)\n",
    "#img_laplacian = tools.saturate_cast_uint8( np.abs( img_sobelX2 + img_sobelY2))\n",
    "\n",
    "## Predefined Laplacian\n",
    "# img_laplacian = tools.saturate_cast_uint8( np.abs( cv2.Laplacian( img, cv2.CV_32F)))\n",
    "\n",
    "tools.multiPlot( 1, 2, ( img_sobel, img_laplacian),\n",
    "                ( 'Sobel', 'Laplacian'),\n",
    "                cmap_tuple=( cm.gray, cm.gray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Scale-space representation of an image\n",
    "\n",
    "We define a continuum of filtered (by a Gaussian) version of the original image by\n",
    "\n",
    "$$J(x,y;t) = G(x,y;t) \\otimes I(x,y) $$\n",
    "\n",
    "where the Gaussian kernel of variance $t = \\sigma ^2$ is given by\n",
    "\n",
    "$$G(x,y;t) = \\frac{1}{2\\pi t} exp ( - \\frac{x^2+y^2}{2 t} ).$$\n",
    "\n",
    "### 4.2.3. Laplacian of Gaussian (LoG)\n",
    "\n",
    "The \"Laplacian of Gaussian\" (LoG) operator is the Laplacian of a filtered (by a Gaussian) version of the image\n",
    "\n",
    "$$LoG_t\\{ I(x,y) \\} = \\Delta \\{ J(x,y;t) \\} =  \\Delta \\{ G(x,y;t) \\otimes I(x,y) \\}$$\n",
    "\n",
    "Due to the distributivity properties of the differentiation of a convolution product, we have\n",
    "\n",
    "$$LoG_t\\{ I(x,y) \\} = G(x,y;t) \\otimes \\Delta \\{ I(x,y) \\} = \\Delta \\{ G(x,y;t) \\} \\otimes I(x,y). $$\n",
    "\n",
    "And we have the following relation between the Laplacian of a Gaussian and its derivative relatively to the parameter $t$\n",
    "\n",
    "$$\\Delta \\{ G(x,y;t) \\} =  \\frac{1}{2\\pi t^3} [ x^2+y^2-2t] exp ( - \\frac{x^2+y^2}{2 t} ) = 2 \\frac {\\partial G(x,y;t)} {\\partial t}.$$\n",
    "\n",
    "So\n",
    "\n",
    "$$LoG_t\\{ I(x,y) \\} = \\Delta \\{ J(x,y;t) \\} = 2 \\frac {\\partial J(x,y;t)} {\\partial t}$$\n",
    "\n",
    "### 4.2.4. Difference of Gaussian (DoG)\n",
    "We may approximate the LoG operator by the Difference of Gaussian (DoG) operator\n",
    "\n",
    "$$\\Delta \\{ J(x,y;\\sigma) \\} \\approx \\frac { 1.6 [J(x,y;1.6 \\sigma) - J(x,y;\\sigma)]} {\\sigma ^2}$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sigma = 0.3 * ( ( ksize - 1) * 0.5 - 1) + 0.8\n",
    "img_float = img.astype( float)\n",
    "ksize = 5\n",
    "sigma = 0.3 * ( ( ksize - 1) * 0.5 - 1) + 0.8     # ksize = 5 --> sigma = 1.1\n",
    "\n",
    "# LoG\n",
    "img_gauss_blur = cv2.GaussianBlur( img_float, (0,0), sigma)\n",
    "\n",
    "kfact = 1.0 / np.power( 2.0, 2 * ( ksize - 2) - 6)\n",
    "img_Gauss_X2 = kfact * cv2.Sobel( img_gauss_blur, cv2.CV_64F, 2, 0, ksize=ksize-2)\n",
    "img_Gauss_Y2 = kfact * cv2.Sobel( img_gauss_blur, cv2.CV_64F, 0, 2, ksize=ksize-2)\n",
    "\n",
    "img_LoG = tools.saturate_cast_uint8( np.abs( img_Gauss_X2 + img_Gauss_Y2))\n",
    "\n",
    "#DoG\n",
    "sigma1 = sigma\n",
    "img_gauss_blur_1 = cv2.GaussianBlur( img_float, (0,0), sigma1)\n",
    "\n",
    "sigma2 = sigma1 * 1.6 # sigma2 = 1.1 * 1.6 = 1.76\n",
    "img_gauss_blur_2 = cv2.GaussianBlur( img_float, ( 0, 0), sigma2, sigma2)\n",
    "\n",
    "img_DoG = tools.saturate_cast_uint8( ( 1.6 * ( img_gauss_blur_2 - img_gauss_blur_1) / ( sigma1 * sigma1)))\n",
    "\n",
    "tools.multiPlot( 1, 2, ( img_LoG, img_DoG),\n",
    "                ( 'LoG', 'DoG'),\n",
    "                cmap_tuple=( cm.gray, cm.gray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Canny algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, fixed\n",
    "\n",
    "img = cv2.imread( 'Images/Pattern_inspection2.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def update( lo_thresh=80, hi_thresh=180, sobel_size=3):\n",
    "    img_canny = cv2.Canny( img, lo_thresh, hi_thresh, apertureSize=sobel_size, L2gradient=True)\n",
    "\n",
    "    tools.multiPlot( 1, 2, ( img, img_canny),\n",
    "                     ( 'Original image', 'Canny'),\n",
    "                     cmap_tuple=( cm.gray, cm.gray))\n",
    "\n",
    "interact(update, lo_thresh = (10, 150, 10), hi_thresh = (120, 240, 10), sobel_size= [3, 5, 7])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
