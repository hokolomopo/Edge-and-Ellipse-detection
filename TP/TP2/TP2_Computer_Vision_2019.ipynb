{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>TP 2 Computer Vision</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import tools\n",
    "\n",
    "from ipywidgets import interact, fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Image thresholding/binarization\n",
    "## 1.1. Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a grayscale image as grayscale and uint between 0 and 255\n",
    "cameraman_grey = cv2.imread( 'Images/cameraman.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Numpy histograms\n",
    "hist_np, bins = np.histogram( cameraman_grey.ravel(),256,[0,256])\n",
    "\n",
    "# OpenCV histograms\n",
    "hist_cv = cv2.calcHist( [cameraman_grey],[0],None,[256],[0,256])\n",
    "\n",
    "# Plot an histogram with matplotlib\n",
    "%matplotlib inline\n",
    "plt.hist(cameraman_grey.ravel(), bins=256, range=(0,255))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Image Thresholding with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "cameraman_threshold = cameraman_grey > 127\n",
    "\n",
    "plt.imshow(cameraman_threshold, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Image Thresholding with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshVal = 100\n",
    "\n",
    "ret, thresh1 = cv2.threshold( cameraman_grey, threshVal, 255, cv2.THRESH_BINARY)\n",
    "ret, thresh2 = cv2.threshold( cameraman_grey, threshVal, 255, cv2.THRESH_BINARY_INV)\n",
    "ret, thresh3 = cv2.threshold( cameraman_grey, threshVal, 255, cv2.THRESH_TRUNC)\n",
    "ret, thresh4 = cv2.threshold( cameraman_grey, threshVal, 255, cv2.THRESH_TOZERO)\n",
    "ret, thresh5 = cv2.threshold( cameraman_grey, threshVal, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "tools.multiPlot( 2, 3, ( cameraman_grey, thresh1, thresh2, thresh3, thresh4, thresh5),\n",
    "                       ( 'Original Image', 'THRESH_BINARY', 'THRESH_BINARY_INV',\n",
    "                        'THRESH_TRUNC', 'THRESH_TOZERO', 'THRESH_TOZERO_INV'),\n",
    "                        cmap_tuple=( cm.gray, cm.gray, cm.gray, cm.gray, cm.gray, cm.gray))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Automatic binarization\n",
    "## 2.1 Otsu's algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a grayscale image as grayscale\n",
    "img = cv2.imread( 'Images/Pattern_inspection2.png', cv2.IMREAD_GRAYSCALE)\n",
    "#img = cv2.imread( 'Images/rice.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# global thresholding\n",
    "ret1,th1 = cv2.threshold( img, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Otsu's thresholding\n",
    "ret2,th2 = cv2.threshold( img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# plot all the images and their histograms\n",
    "\n",
    "tools.multiPlot( 2, 2, ( img, img, th1, th2),\n",
    "                       ( 'Original Image', 'Histogram', 'Global Thresholding (v=150)', \"Otsu's Thresholding\"),\n",
    "                        cmap_tuple=( cm.gray, cm.gray, cm.gray, cm.gray),\n",
    "                        dispType_tuple=( 'image', 'histogram', 'image', 'image'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Otsu's binarization by parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a grayscale image as grayscale\n",
    "img = cv2.imread( 'Images/rice.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Otsu's thresholding\n",
    "ret1,th1 = cv2.threshold( img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Otsu's thresholding by parts\n",
    "ret21,th21 = cv2.threshold( img[:53,:], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "ret22,th22 = cv2.threshold( img[53:106,:], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "ret23,th23 = cv2.threshold( img[106:159,:], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "ret24,th24 = cv2.threshold( img[159:212,:], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "ret25,th25 = cv2.threshold( img[212:,:], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Combine parts\n",
    "th2 = np.concatenate( ( th21, th22, th23, th24, th25), axis=0)\n",
    "\n",
    "# plot all the images and their histograms\n",
    "tools.multiPlot( 2, 2, ( img, img, th1, th2),\n",
    "                       ( 'Original Image', 'Histogram', \"Otsu's Thresholding\", \"Otsu's Thresholding by part\"),\n",
    "                        cmap_tuple=( cm.gray, cm.gray, cm.gray, cm.gray),\n",
    "                        dispType_tuple=('image', 'histogram', 'image', 'image'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a grayscale image as grayscale\n",
    "img = cv2.imread( 'Images/rice.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "light_gradient = np.arange( start=132, stop=-133, step=-1) / 3\n",
    "non_uniform_lightning = ( np.reshape( light_gradient, ( 265, 1))) * np.ones( ( 1, 250), dtype=int)\n",
    "\n",
    "img_nu = tools.saturate_cast_uint8( img + non_uniform_lightning)\n",
    "\n",
    "# Otsu's thresholding\n",
    "ret1,th1 = cv2.threshold( img_nu, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Otsu's thresholding by parts\n",
    "ret21,th21 = cv2.threshold( img_nu[:53,:], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "ret22,th22 = cv2.threshold( img_nu[53:106,:], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "ret23,th23 = cv2.threshold( img_nu[106:159,:], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "ret24,th24 = cv2.threshold( img_nu[159:212,:], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "ret25,th25 = cv2.threshold( img_nu[212:,:], 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Combine parts\n",
    "th2 = np.concatenate( ( th21, th22, th23, th24, th25), axis=0)\n",
    "\n",
    "# plot all the images and their histograms\n",
    "tools.multiPlot( 2, 3, ( img, non_uniform_lightning, img_nu, img_nu, th1, th2),\n",
    "                       ( 'Original Image', 'Non-uniform lightning', 'Transformed image',\n",
    "                         'Histogram', \"Otsu's Thresholding\", \"Otsu's Thresholding by part\"),\n",
    "                        cmap_tuple=( cm.gray, cm.gray, cm.gray, cm.gray, cm.gray, cm.gray),\n",
    "                        dispType_tuple=('image', 'image', 'image', 'histogram', 'image', 'image'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Bilateral filtering\n",
    "\n",
    "The goal of this filter is to reduce the noise while keeping the edges sharp. The function is defined as:\n",
    "\n",
    "$I^{filtered}(x)=\\frac{1}{W_p(x)}\\sum_{x_i\\in\\Omega(x)}{I(x_i)f(||I(x_i)-I(x)||)g(||x_i-x||)}$\n",
    "\n",
    "$W_P(x) = \\sum_{x_i\\in\\Omega(x)}{f(||I(x_i)-I(x)||)g(||x_i-x||)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread( 'Images/boat.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def update(omega=10, sigma_color=20, sigma_space=50):\n",
    "    img_bilat = cv2.bilateralFilter( img, omega, sigma_color, sigma_space)\n",
    "\n",
    "    tools.multiPlot( 1, 2, ( img, img_bilat), ( 'Original image', 'Bilateral filtering'),\n",
    "                       cmap_tuple=( cm.gray, cm.gray))\n",
    "\n",
    "interact(update, omega = [1, 5, 10, 20, 30] , sigma_color = (10, 250, 10), sigma_space=(10,250,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread( 'Images/boat.png', cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.imread( 'Images/Building.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "def update(omega=10, sigma_color=20, sigma_space=50):\n",
    "    img_bilat = cv2.bilateralFilter( img, omega, sigma_color, sigma_space)\n",
    "\n",
    "    tools.multiPlot( 1, 2, ( img[600:900,300:700], img_bilat[600:900,300:700]), ( 'Original image', 'Bilateral filtering'),\n",
    "                       cmap_tuple=( cm.gray, cm.gray))\n",
    "\n",
    "interact(update, omega = [1, 5, 10, 20, 30] , sigma_color = (10, 250, 10), sigma_space=(10,250,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Edge detection (2)\n",
    "## 4.1. Automatic Canny with Otsu's algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread( 'Images/Pattern_inspection2.png', cv2.IMREAD_GRAYSCALE)\n",
    "#img = cv2.imread( 'Images/Building.png', cv2.IMREAD_GRAYSCALE)\n",
    "#img = cv2.imread( 'Images/Road.png', cv2.IMREAD_GRAYSCALE)\n",
    "#img = cv2.imread( 'Images/1_HQ00020.png', cv2.IMREAD_GRAYSCALE)\n",
    "#img = cv2.imread( 'Images/image.000078.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "hiThreshold, _ = cv2.threshold( img, thresh=0, maxval=255, type=( cv2.THRESH_BINARY + cv2.THRESH_OTSU))\n",
    "\n",
    "fLoHiRatio = 0.3\n",
    "edges = cv2.Canny( img, fLoHiRatio * hiThreshold, hiThreshold, apertureSize=3, L2gradient=False)\n",
    "\n",
    "# plot all the images\n",
    "tools.multiPlot( 1, 1, ( edges,),\n",
    "                       ( 'Edges',),\n",
    "                        cmap_tuple=( cm.gray,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Automatic Canny with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread( 'Images/Pattern_inspection2.png', cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.imread( 'Images/Building.png', cv2.IMREAD_GRAYSCALE)\n",
    "#img = cv2.imread( 'Images/Road.png', cv2.IMREAD_GRAYSCALE)\n",
    "#img = cv2.imread( 'Images/1_HQ00020.png', cv2.IMREAD_GRAYSCALE)\n",
    "#img = cv2.imread( 'Images/image.000078.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# compute the median of the single channel pixel intensities\n",
    "med = np.median( img)\n",
    " \n",
    "# apply automatic Canny edge detection using the computed median\n",
    "sigma = 0.3\n",
    "loThreshold = int( max( 0, (1.0 - sigma) * med))\n",
    "hiThreshold = int( min( 255, (1.0 + sigma) * med))\n",
    "\n",
    "edges = cv2.Canny( img, loThreshold, hiThreshold, apertureSize=3, L2gradient=False)\n",
    "\n",
    "# plot all the images\n",
    "tools.multiPlot( 1, 1, ( edges,),\n",
    "                       ( 'Edges',),\n",
    "                        cmap_tuple=( cm.gray,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Prefiltering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread( 'Images/Pattern_inspection2.png', cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.imread( 'Images/Building.png', cv2.IMREAD_GRAYSCALE)\n",
    "#img = cv2.imread( 'Images/Road.png', cv2.IMREAD_GRAYSCALE)\n",
    "#img = cv2.imread( 'Images/1_HQ00020.png', cv2.IMREAD_GRAYSCALE)\n",
    "#img = cv2.imread( 'Images/image.000078.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "iGausKernelSize = 11\n",
    "imgFilt = cv2.GaussianBlur( img, ( iGausKernelSize, iGausKernelSize), 0)\n",
    "\n",
    "iReducFactor = 2\n",
    "iStart = iReducFactor // 2\n",
    "imgReduc = imgFilt[iStart::iReducFactor, iStart::iReducFactor]\n",
    "   \n",
    "# compute the median of the single channel pixel intensities\n",
    "med = np.median( imgReduc)\n",
    " \n",
    "# apply automatic Canny edge detection using the computed median\n",
    "sigma = 0.3\n",
    "loThreshold = int( max( 0, (1.0 - sigma) * med))\n",
    "hiThreshold = int( min( 255, (1.0 + sigma) * med))\n",
    "\n",
    "edges = cv2.Canny( imgReduc, loThreshold, hiThreshold, apertureSize=3, L2gradient=False)\n",
    "\n",
    "# plot all the images\n",
    "tools.multiPlot( 1, 1, ( edges,),\n",
    "                       ( 'Edges',),\n",
    "                        cmap_tuple=( cm.gray,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Edge location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the coordinates of the edge points from the 'edges' image\n",
    "width = imgReduc.shape[1]\n",
    "height = imgReduc.shape[0]\n",
    "grid = np.mgrid[ 0:height, 0:width]\n",
    "X = grid[1][edges > 0]\n",
    "Y = grid[0][edges > 0]\n",
    "\n",
    "# Recreate the 'edges2' image from the edge points location\n",
    "edges2 = np.zeros_like( imgReduc)\n",
    "edges2[ Y, X] = 255\n",
    "\n",
    "# Compute the gradient vector and orientation at the edge points \n",
    "imgGradX = cv2.Sobel( imgReduc, cv2.CV_32F, 1, 0, ksize=3)\n",
    "imgGradY = cv2.Sobel( imgReduc, cv2.CV_32F, 0, 1, ksize=3)\n",
    "gradX = imgGradX[edges > 0]\n",
    "gradY = imgGradY[edges > 0]\n",
    "gradTheta = np.arctan2( gradY, gradX)\n",
    "\n",
    "# Compute the orientation of the vectors from the origin to the line of support (tangent) of the edges\n",
    "lineTheta = np.where( X * gradX + Y * gradY < 0, gradTheta + np.pi, gradTheta)\n",
    "lineTheta = np.where( lineTheta < 0.0, lineTheta + 2.0 * np.pi, lineTheta)\n",
    "\n",
    "# plot all the images\n",
    "tools.multiPlot( 1, 1, ( edges2,),\n",
    "                       ( 'Edges',),\n",
    "                        cmap_tuple=( cm.gray,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
